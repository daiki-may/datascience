{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各種ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "import datetime\n",
    "import collections\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn.datasets\n",
    "\n",
    "# 数値計算に使うライブラリ\n",
    "import scipy as sp\n",
    "from scipy import stats as st\n",
    "\n",
    "# グラフを描画するライブラリ\n",
    "sns.set()\n",
    "\n",
    "# 統計モデルを推定するライブラリ\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.anova as anova # 分散分析するライブラリ\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd # Tukeyの多重比較するライブラリ\n",
    "\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime as dt\n",
    "from sklearn.ensemble import  RandomForestRegressor as RFR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import optuna.integration.lightgbm as lgb_o\n",
    "import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "# 評価指標\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV to DataFrameの操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単数CSVファイルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teach_df = pd.read_csv('teach.csv', header=None)\n",
    "\n",
    "#必要ならばindex消去\n",
    "teach_df = teach_df.drop(index=0)\n",
    "\n",
    "#列名を指定して数値をint型にする\n",
    "teach_df['Number of Person'] = teach_df['Number of Person'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSVファイルの結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llist = []\n",
    "allfiles = glob.glob('Data/*.csv')\n",
    "    \n",
    "for file in allfiles:\n",
    "    llist.append(pd.read_csv(file,header=None))\n",
    "df = pd.concat(llist, sort=False)\n",
    "df = df.drop(index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameのカラム名変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0:'Date', 1:'Time', 2:'From', 3:'Weekday/Holidays', 4:'Train Line', 5:'Station', 6:'Population'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameソートする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引数に\"ascending=False\"で逆になる\n",
    "df = df.sort_values(['Date', 'Time'])\n",
    "\n",
    "#指定列の合計でまとめる\n",
    "df = df.groupby('Date').sum()\n",
    "\n",
    "#１列のみでソートする\n",
    "df = df.sort_values('Date', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日にちや時間をdatetime型にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "#splitできない問題に対する解\n",
    "#時間のみ（上）、日にちのみ（下）\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.time\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "\n",
    "#時間はstr型なのでint型にして計算できるようにする\n",
    "df['Time'] = df['Time'].astype(int)\n",
    "df['Time'] = df['Time'].astype('float64')\n",
    "\n",
    "#datetime型の時間や日にちの範囲指定\n",
    "df = df[df['Date'] >= datetime.datetime(year=2020, month=2, day=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameの不要なカラム削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['From', 'Time','Weekday/Holidays', 'Train Line'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame横に結合＆新しい列を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onで合わせている\n",
    "df_newconcat = pd.merge(df2, df1, on='Date', how='left')\n",
    "\n",
    "#新しい列を作成して追加\n",
    "teach_df = pd.concat([teach_df,pd.DataFrame(teach_df.sum(axis=1),columns=['Total'])],axis=1)\n",
    "teach_df = pd.concat([teach_df,pd.DataFrame(app_list,columns=['Train_Total'])],axis=1)\n",
    "\n",
    "#DataFrameを横に結合\n",
    "df = pd.concat([df_0612, df_0613, df_0626, df_0627], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrameのインデックスの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "\n",
    "#インデックスを指定して行削除\n",
    "df = df.drop(0)\n",
    "\n",
    "#条件にマッチしたIndexを取得\n",
    "drop_index = df.index[df['Ex4'] < 30]\n",
    "#条件にマッチしたIndexを削除\n",
    "df = df.drop(drop_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 図の作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形図のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn_analyzer import regplot\n",
    "import seaborn as sns\n",
    "\n",
    "#DataFrameの列名で指定\n",
    "regplot.linear_plot(x='Train_Total', y='Total', data=teach_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各要素間の相関分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn_analyzer import CustomPairPlot\n",
    "import seaborn as sns\n",
    "\n",
    "#DataFrameを入れるだけ\n",
    "cp = CustomPairPlot()\n",
    "cp.pairanalyzer(last_df, lowerkind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 箱ひげ図"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrameをくっつけて箱ひげ図をプロット\n",
    "concat_df = pd.concat([df_ex1, df_ex2, df_ex3, df_ex4], axis=1)\n",
    "# concat_df = pd.concat([df_1_more60, df_2_more60, df_3_more60, df_4_more60], axis=0, join='outer')\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(10,7)})\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(data = concat_df, color='r')\n",
    "plt.ylim(0, 400)\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data = concat_df, sym=\"\")\n",
    "# sns.boxplot(data = concat_df, whis=33)\n",
    "plt.ylim(0, 35)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 円グラフ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy配列にして円グラフにする\n",
    "\n",
    "visi_na061213=[]\n",
    "na = visi_li061213\n",
    "for i in range(len(na)):\n",
    "    visi_na061213.append(na[i][1])\n",
    "visi_na061213 = np.array(visi_na061213)  \n",
    "\n",
    "plt.pie(visi_na061213, counterclock=False, startangle=90, autopct=\"%1.1f%%\")\n",
    "plt.title('Ex1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 移動平均を用いてグラフをプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "#datetimeに変換\n",
    "df_visitor_0612['Time'] = pd.to_datetime(df_visitor_0612['Time'])\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "colors3 = [\"royalblue\", \"skyblue\", \"y\", \"red\"]\n",
    "\n",
    "x1 = df_visitor_0612.set_index('Time')\n",
    "\n",
    "#移動平均をとる\n",
    "y1 = pd.DataFrame(OrderedDict({'SMA' : df_visitor_0612['Visitor'].rolling(window=60).mean(),}))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m:%d'))\n",
    "\n",
    "plt.plot(x1.index, y1, c=colors3[0], label = \"Ex1 on Sat\")\n",
    "# plt.plot(x2.index, y2, linestyle=\"dashed\", c=colors3[0], label = \"Ex1 on Sun\")\n",
    "\n",
    "ax.legend(loc='upper left', fontsize=13.5)\n",
    "plt.title('Number of Visits during the Experiment')\n",
    "plt.xlabel('Date Time')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.xticks(rotation=70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シンプルな棒グラフ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_values = ['20210612', '20210613', '20210626', '20210627']\n",
    "c_values = [df_visitor_0612_10['Visitor'].sum(), df_visitor_0613_10['Visitor'].sum(), df_visitor_0626_10['Visitor'].sum(), df_visitor_0627_10['Visitor'].sum()]\n",
    "\n",
    "my_dict = {\"Date\": a_values, \"Number of visitors per day\":c_values}\n",
    "\n",
    "total_df = pd.DataFrame.from_dict(my_dict)\n",
    "df_total = total_df.set_index('Date')\n",
    "\n",
    "#plt.plot(df_total.index, df_total['Average time spent in the booth per day'])\n",
    "color_list = [\"b\", \"b\", \"sandybrown\", \"sandybrown\", \"g\",\"g\",\"r\",\"r\",\"r\",\"r\"]\n",
    "total_df.plot.bar(x='Date', y='Number of visitors per day', ylim=[1000, 9000], legend=False, color=color_list)\n",
    "#total_df.plot(x=\"Date\", y=\"Sales Figure\")\n",
    "\n",
    "plt.title('Number of visits per day during Experiment')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of visits per day')\n",
    "plt.xticks(rotation=70)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(learn_df)\n",
    "scaler.transform(learn_df)\n",
    "scaler.transform(test_df)\n",
    "learn_df_std = pd.DataFrame(scaler.transform(learn_df), columns=learn_df.columns)\n",
    "test_df_std = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'vervose': 0\n",
    "}\n",
    "\n",
    "RANDOM_STATE = 10\n",
    "\n",
    "# 学習データと評価データの割合\n",
    "TEST_SIZE = 0.2\n",
    "score_list = []\n",
    "\n",
    "\n",
    "x_train = learn_df_std[['Total precipitation', 'Average temperature', 'Total precipitation','Number of masculine', 'Total Number of masculine']]\n",
    "y_train = learn_df_std['Total']\n",
    "x_test = test_df_std[['Total precipitation', 'Average temperature', 'Total Number of masculine']]\n",
    "y_test = test_df_std['Total']\n",
    "\n",
    "# # 学習データと評価データを作成\n",
    "# x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, 0:df.shape[1]-1],\n",
    "#                                                     df.iloc[:, df.shape[1]-1],\n",
    "#                                                     test_size=TEST_SIZE,\n",
    "#                                                     random_state=RANDOM_STATE)\n",
    "\n",
    "# trainのデータセットの3割をモデル学習時のバリデーションデータとして利用する\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train,\n",
    "                                                    y_train,\n",
    "                                                    test_size=TEST_SIZE,\n",
    "                                                    random_state=RANDOM_STATE)\n",
    "\n",
    "# LightGBMを利用するのに必要なフォーマットに変換\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_eval = lgb.Dataset(x_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "# ベストなパラメータ、途中経過を保存する\n",
    "params = {\n",
    "    'objective': 'mean_squared_error',\n",
    "    'metric': 'mae',\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}\n",
    "\n",
    "best_params, history = {}, []\n",
    "\n",
    "# LightGBM学習\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=200,\n",
    "                valid_sets=[lgb_train, lgb_eval],\n",
    "                early_stopping_rounds=50\n",
    "               )\n",
    "\n",
    "best_params = gbm.params\n",
    "best_params\n",
    "\n",
    "# LightGBM推論\n",
    "y_pred = gbm.predict(x_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "\n",
    "\n",
    "# 評価\n",
    "def calculate_scores(true, pred):\n",
    "    \"\"\"全ての評価指標を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true (np.array)       : 実測値\n",
    "    pred (np.array)       : 予測値\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scores (pd.DataFrame) : 各評価指標を纏めた結果\n",
    "\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    scores = pd.DataFrame({'R2': r2_score(true, pred),\n",
    "                          'MAE': mean_absolute_error(true, pred),\n",
    "                          'MSE': mean_squared_error(true, pred),\n",
    "                          'RMSE': np.sqrt(mean_squared_error(true, pred)),\n",
    "                          'MAPE' : mean_absolute_percentage_error(true, pred)},\n",
    "                           index = ['scores'])\n",
    "    return scores\n",
    "scores = calculate_scores(y_test, y_pred)\n",
    "score_list.append(scores)\n",
    "print(\"=\"*50)\n",
    "print(scores)\n",
    "\n",
    "print(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# X_train = learn_df[[\"ble_num\", \"final_address\"]]\n",
    "X_train = learn_df100[['Train_Total', 'Average temperature', 'Total precipitation', 'Number of masculine', 'Total Number of masculine']]\n",
    "y_train = learn_df100['Total']\n",
    "X_test = test_df100[['Train_Total', 'Average temperature', 'Total precipitation', 'Number of masculine', 'Total Number of masculine']] \n",
    "y_test = test_df100['Total']\n",
    "\n",
    "search_params = {\n",
    "    'n_estimators'      : [5, 10, 20, 30, 50,100],\n",
    "    #\"max_features\": [1,10,100,500,1000,3000,len(all_learn_df[test_rasp_id][0][\"ble_num\"].tolist())],\n",
    "    'random_state'      : [2525],\n",
    "    'n_jobs'            : [1],\n",
    "    'min_samples_split' : [3, 5, 10, 25, 50, 100],\n",
    "    'max_depth'         : [3, 5, 10, 25, 50, 100]\n",
    "}\n",
    "gsr = GridSearchCV(\n",
    "    RFR(),\n",
    "    search_params,\n",
    "    cv = 3,\n",
    "    n_jobs = -1,\n",
    "    verbose=True\n",
    ")\n",
    "gsr.fit(X_train, y_train)\n",
    "y_pred = gsr.predict(X_test)\n",
    "RFR_MAE = mean_absolute_error(y_test, y_pred)\n",
    "RFR_MAPE = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"RFR\")\n",
    "print(\"MAE: {:.2f}\".format(RFR_MAE))\n",
    "print(\"MAPE: {:.5f}\".format(RFR_MAPE))\n",
    "\n",
    "print(\"RFR finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形回帰モデル(単回帰分析)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#単回帰分析\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "\n",
    "X_train = np.array(learn_df['Train_Total']).reshape(-1, 1)\n",
    "y_train = np.array(learn_df['Total']).reshape(-1, 1)\n",
    "X_test = np.array(test_df['Train_Total']).reshape(-1, 1) \n",
    "y_test = np.array(test_df['Total']).reshape(-1, 1)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train) # 線形モデルの重みを学習\n",
    "\n",
    "y_pred = lr.predict(X_test) # 検証データを用いて目的変数を予測\n",
    "y_train_pred = lr.predict(X_train) # 学習データに対する目的変数を予測\n",
    "print('MSE train data: ', mean_squared_error(y_train, y_train_pred)) # 学習データを用いたときの平均二乗誤差を出力\n",
    "print('MSE test data: ', mean_squared_error(y_test, y_pred))         # 検証データを用いたときの平均二乗誤差を出力\n",
    "\n",
    "RFR_MAE = mean_absolute_error(y_test, y_pred)\n",
    "RFR_MAPE = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MAE: {:.6f}\".format(RFR_MAE))\n",
    "print(\"MAPE: {:.6f}\".format(RFR_MAPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形回帰モデル(重回帰分析)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重回帰分析\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "\n",
    "X_train = learn_df300[['Total precipitation', 'Average temperature', 'Total precipitation','Number of masculine', 'Total Number of masculine']].values\n",
    "y_train = np.array(learn_df300['Total']).reshape(-1, 1)\n",
    "X_test = test_df300[['Total precipitation', 'Average temperature', 'Total precipitation','Number of masculine', 'Total Number of masculine']].values\n",
    "y_test = np.array(test_df300['Total']).reshape(-1, 1)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train) # 線形モデルの重みを学習\n",
    "\n",
    "y_pred = lr.predict(X_test) # 検証データを用いて目的変数を予測\n",
    "y_train_pred = lr.predict(X_train) # 学習データに対する目的変数を予測\n",
    "print('MSE train data: ', mean_squared_error(y_train, y_train_pred)) # 学習データを用いたときの平均二乗誤差を出力\n",
    "print('MSE test data: ', mean_squared_error(y_test, y_pred))         # 検証データを用いたときの平均二乗誤差を出力\n",
    "\n",
    "RFR_MAE = mean_absolute_error(y_test, y_pred)\n",
    "RFR_MAPE = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"MAE: {:.6f}\".format(RFR_MAE))\n",
    "print(\"MAPE: {:.6f}\".format(RFR_MAPE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MAPE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss = (outputs - targets).abs() / (targets.abs() + 1e-8)\n",
    "        return loss        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "import torch\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# X_train = np.array(learn_df500['Train_Total']).reshape(-1, 1)\n",
    "# y_train = np.array(learn_df500['Total']).reshape(-1, 1)\n",
    "# X_test = np.array(test_df500['Train_Total']).reshape(-1, 1)\n",
    "# y_test = np.array(test_df500['Total']).reshape(-1, 1)\n",
    "\n",
    "X_train = learn_df_std300[['Train_Total', 'Average temperature', 'Total precipitation', 'Number of masculine', 'Total Number of masculine']].values\n",
    "y_train = np.array(learn_df_std300['Total']).reshape(-1, 1)\n",
    "X_test = test_df_std300[['Train_Total', 'Average temperature', 'Total precipitation', 'Number of masculine', 'Total Number of masculine']].values\n",
    "y_test = np.array(test_df_std300['Total']).reshape(-1, 1)\n",
    "\n",
    "clf = TabNetRegressor(optimizer_fn=torch.optim.Adam,optimizer_params=dict(lr=0.5))  #TabNetRegressor()\n",
    "clf.fit(X_train, y_train, loss_fn=torch.nn.functional.l1_loss, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(y_test, clf.predict(X_test))\n",
    "print('MAE : {:.5f}'.format(MAE) )\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "RFR_MAP = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"MAPE: {:.6f}\".format(RFR_MAP))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
